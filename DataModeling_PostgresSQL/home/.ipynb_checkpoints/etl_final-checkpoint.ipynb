{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 files found in data/song_data\n",
      "1/83 files processed.\n",
      "2/83 files processed.\n",
      "3/83 files processed.\n",
      "4/83 files processed.\n",
      "5/83 files processed.\n",
      "6/83 files processed.\n",
      "7/83 files processed.\n",
      "8/83 files processed.\n",
      "9/83 files processed.\n",
      "10/83 files processed.\n",
      "11/83 files processed.\n",
      "12/83 files processed.\n",
      "13/83 files processed.\n",
      "14/83 files processed.\n",
      "15/83 files processed.\n",
      "16/83 files processed.\n",
      "17/83 files processed.\n",
      "18/83 files processed.\n",
      "19/83 files processed.\n",
      "20/83 files processed.\n",
      "21/83 files processed.\n",
      "22/83 files processed.\n",
      "23/83 files processed.\n",
      "24/83 files processed.\n",
      "25/83 files processed.\n",
      "26/83 files processed.\n",
      "27/83 files processed.\n",
      "28/83 files processed.\n",
      "29/83 files processed.\n",
      "30/83 files processed.\n",
      "31/83 files processed.\n",
      "32/83 files processed.\n",
      "33/83 files processed.\n",
      "34/83 files processed.\n",
      "35/83 files processed.\n",
      "36/83 files processed.\n",
      "37/83 files processed.\n",
      "38/83 files processed.\n",
      "39/83 files processed.\n",
      "40/83 files processed.\n",
      "41/83 files processed.\n",
      "42/83 files processed.\n",
      "43/83 files processed.\n",
      "44/83 files processed.\n",
      "45/83 files processed.\n",
      "46/83 files processed.\n",
      "47/83 files processed.\n",
      "48/83 files processed.\n",
      "49/83 files processed.\n",
      "50/83 files processed.\n",
      "51/83 files processed.\n",
      "52/83 files processed.\n",
      "53/83 files processed.\n",
      "54/83 files processed.\n",
      "55/83 files processed.\n",
      "56/83 files processed.\n",
      "57/83 files processed.\n",
      "58/83 files processed.\n",
      "59/83 files processed.\n",
      "60/83 files processed.\n",
      "61/83 files processed.\n",
      "62/83 files processed.\n",
      "63/83 files processed.\n",
      "64/83 files processed.\n",
      "65/83 files processed.\n",
      "66/83 files processed.\n",
      "67/83 files processed.\n",
      "68/83 files processed.\n",
      "69/83 files processed.\n",
      "70/83 files processed.\n",
      "71/83 files processed.\n",
      "72/83 files processed.\n",
      "73/83 files processed.\n",
      "74/83 files processed.\n",
      "75/83 files processed.\n",
      "76/83 files processed.\n",
      "77/83 files processed.\n",
      "78/83 files processed.\n",
      "79/83 files processed.\n",
      "80/83 files processed.\n",
      "81/83 files processed.\n",
      "82/83 files processed.\n",
      "83/83 files processed.\n",
      "31 files found in data/log_data\n",
      "1/31 files processed.\n",
      "2/31 files processed.\n",
      "3/31 files processed.\n",
      "4/31 files processed.\n",
      "5/31 files processed.\n",
      "6/31 files processed.\n",
      "7/31 files processed.\n",
      "8/31 files processed.\n",
      "9/31 files processed.\n",
      "10/31 files processed.\n",
      "11/31 files processed.\n",
      "12/31 files processed.\n",
      "13/31 files processed.\n",
      "14/31 files processed.\n",
      "15/31 files processed.\n",
      "16/31 files processed.\n",
      "17/31 files processed.\n",
      "18/31 files processed.\n",
      "19/31 files processed.\n",
      "20/31 files processed.\n",
      "21/31 files processed.\n",
      "22/31 files processed.\n",
      "23/31 files processed.\n",
      "24/31 files processed.\n",
      "25/31 files processed.\n",
      "26/31 files processed.\n",
      "27/31 files processed.\n",
      "28/31 files processed.\n",
      "29/31 files processed.\n",
      "30/31 files processed.\n",
      "31/31 files processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *\n",
    "\n",
    "\n",
    "def process_song_file(cur, filepath):\n",
    "   \n",
    "    if filepath:\n",
    "        song_data = []\n",
    "        for fl in filepath:\n",
    "            # open song fil\n",
    "            fl_df = pd.read_json(filepath , lines=True)\n",
    "            for data in fl_df.values:\n",
    "\n",
    "                artist_id = data[0]\n",
    "                artist_lat  = data[1]\n",
    "                artist_location = data[2]\n",
    "                artist_lng  = data[3]\n",
    "                artist_name = data[4]\n",
    "                duration  = data[5]\n",
    "                song_id   = data[7]\n",
    "                title     = data[8]\n",
    "                year      = data[9]\n",
    "\n",
    "                #song_data.append([song_id,title, artist_id, year, duration])\n",
    "                #artist_data.append([artist_id, artist_name, artist_location, artist_lat, artist_lng])\n",
    "                # insert artist record\n",
    "                cur.execute(artist_table_insert, [artist_id, artist_name, artist_location, artist_lat, artist_lng])    \n",
    "                # insert song record\n",
    "                cur.execute(song_table_insert, [song_id, title, artist_id, year, duration])\n",
    "            \n",
    "                \n",
    "\n",
    "    #conn.commit()\n",
    "\n",
    "def process_log_file(cur, filepath):\n",
    "    #print('lalallala')\n",
    "    if filepath:\n",
    "        # Dict utilized just to convert colum_labels to a dictonary with time_data information\n",
    "        idx_column_labels = {\n",
    "            0:'timestamp', \n",
    "            1:'hour',\n",
    "            2:'day', \n",
    "            3:'week_year', \n",
    "            4:'month', \n",
    "            5:'year', \n",
    "            6:'weekday'\n",
    "        }\n",
    "\n",
    "    # open log file\n",
    "    fl_df = pd.read_json(filepath , lines=True)\n",
    "    # filter by NextSong action\n",
    "    log_next_song_df = fl_df.loc[fl_df['page'] == 'NextSong']\n",
    "    t = pd.to_datetime(log_next_song_df['ts'])\n",
    "    # Setup of the variables with correct datatype\n",
    "    # convert timestamp column to datetime\n",
    "    timestamp = (t)\n",
    "    hour = (t.dt.hour)\n",
    "    day = (t.dt.day)\n",
    "    week_of_year = (t.dt.weekofyear)\n",
    "    month = (t.dt.month)\n",
    "    year = (t.dt.year)\n",
    "    week_day = (t.dt.weekday)\n",
    "\n",
    "    # Setup time_data to a list of list\n",
    "    time_data = [\n",
    "         timestamp.tolist(), hour.tolist(), \n",
    "         day.tolist(), week_of_year.tolist(), \n",
    "         month.tolist(), year.tolist(), week_day.tolist()\n",
    "    ]\n",
    "\n",
    "    column_labels = dict()\n",
    "\n",
    "    # Combine time_data and column labels\n",
    "    for i in range(0,len(time_data)):\n",
    "        try:\n",
    "            _column = idx_column_labels[i]\n",
    "        except:\n",
    "            print('List with more columns than expected!')\n",
    "            break;\n",
    "\n",
    "        column_labels[_column] = time_data[i]\n",
    "\n",
    "    # insert time data records\n",
    "    time_df = pd.DataFrame(data = column_labels)\n",
    "    for i, row in time_df.iterrows():\n",
    "        cur.execute(time_table_insert, list(row))\n",
    "    # load user table\n",
    "    user_df = fl_df[['userId', 'firstName', 'lastName', 'gender', 'level']].copy(deep=False)\n",
    "    user_df = user_df.drop_duplicates(keep = False, inplace = False)\n",
    "    for i, row in user_df.iterrows():\n",
    "        cur.execute(user_table_insert, row)\n",
    "\n",
    "    #insert songplay record   \n",
    "    for index, row in fl_df.loc[fl_df['page'] == 'NextSong'].iterrows():\n",
    "        # get songid and artistid from song and artist tables\n",
    "        cur.execute(song_select, (row.song, row.artist))\n",
    "        #cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "        results = cur.fetchone()\n",
    "        if results:\n",
    "            songid, artistid = results\n",
    "            #print()\n",
    "            songplay_data = [row.ts, row.userId, row.level, songid, artistid, row.sessionId, row.location, row.userAgent]\n",
    "            cur.execute(songplay_table_insert, songplay_data )\n",
    "        else:\n",
    "            songid, artistid = None, None\n",
    "\n",
    "    #conn.commit()\n",
    "\n",
    "\n",
    "def process_data(cur, conn, filepath, func):\n",
    "    # get all files matching extension from directory\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # get total number of files found\n",
    "    num_files = len(all_files)\n",
    "    print('{} files found in {}'.format(num_files, filepath))\n",
    "\n",
    "    # iterate over files and process\n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "        #print(datafile)\n",
    "        #break;\n",
    "        func(cur, datafile)\n",
    "        conn.commit()\n",
    "        print('{}/{} files processed.'.format(i, num_files))\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    process_data(cur, conn, filepath='data/song_data', func=process_song_file)\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
